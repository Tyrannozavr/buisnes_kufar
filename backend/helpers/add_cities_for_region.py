#!/usr/bin/env python3
"""
Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ Ğ»ÑĞ±Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ° Ğ Ğ¾ÑÑĞ¸Ğ¸
ĞĞµ ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ID ÑĞ²Ğ½Ğ¾ - Ğ‘Ğ” Ğ°Ğ²Ñ‚Ğ¾Ğ¸Ğ½ĞºÑ€ĞµĞ¼ĞµĞ½Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚
"""

import asyncio
import sys
import os
from datetime import datetime
from pathlib import Path
import httpx
from bs4 import BeautifulSoup
import re

sys.path.insert(0, str(Path(__file__).parent))

from app.db.base import AsyncSessionLocal
from app.api.common.models.region import Region
from app.api.common.models.city import City
from sqlalchemy import select


async def parse_cities_from_superresearch(page_id: int):
    """ĞŸĞ°Ñ€ÑĞ¸Ñ‚ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ° Ñ superresearch.ru Ğ¿Ğ¾ page_id"""
    url = f"https://superresearch.ru/?id={page_id}"
    
    print(f"ğŸ“¡ ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ° Ñ {url}")
    
    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.get(url)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        full_text = soup.get_text()
        
        pattern = r'Ğ“Ğ¾Ñ€Ğ¾Ğ´Ğ°\s+.*?\s+Ğ²\s+Ğ°Ğ»Ñ„Ğ°Ğ²Ğ¸Ñ‚Ğ½Ğ¾Ğ¼\s+Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ:'
        match = re.search(pattern, full_text)
        
        cities = []
        
        if match:
            start_pos = match.end()
            text_after_marker = full_text[start_pos:]
            lines = text_after_marker.split('\n')
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                if len(line) > 2 and len(line) < 60 and line[0].isupper():
                    if not any(skip in line for skip in ['Â©', 'Ğ¢ĞµĞ».', 'Ğ Ğ¾ÑÑĞ¸Ñ', 'ÑƒĞ».', 'Ğ´.', 'Ğ¿.', '+7']):
                        cities.append(line)
                        if 'Â©' in line or 'Ğ¢ĞµĞ».' in line:
                            break
        
        # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹
        unique_cities = []
        seen = set()
        for city in cities:
            city_normalized = ' '.join(city.split()).strip()
            if 2 < len(city_normalized) < 50 and any(c.isalpha() for c in city_normalized):
                city_key = city_normalized.lower()
                if city_key not in seen:
                    seen.add(city_key)
                    unique_cities.append(city_normalized)
        
        print(f"âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ¾Ğ²: {len(unique_cities)}")
        if unique_cities:
            print("ĞŸĞµÑ€Ğ²Ñ‹Ğµ 10 Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ¾Ğ²:")
            for i, city in enumerate(unique_cities[:10], 1):
                print(f"  {i}. {city}")
        
        return unique_cities


async def add_cities_for_region(region_name: str, page_id: int):
    """Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ° Ğ´Ğ»Ñ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğ³Ğ¾ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ°"""
    
    print(f"\n{'='*60}")
    print(f"ğŸŒ Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ¾Ğ² Ğ´Ğ»Ñ: {region_name}")
    print(f"{'='*60}\n")
    
    # ĞŸĞ°Ñ€ÑĞ¸Ğ¼ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°
    cities_list = await parse_cities_from_superresearch(page_id)
    
    if not cities_list:
        print("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°")
        return
    
    async with AsyncSessionLocal() as db:
        # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½
        region_result = await db.execute(
            select(Region).where(Region.name == region_name)
        )
        region = region_result.scalar_one_or_none()
        
        if not region:
            print(f"âŒ Ğ ĞµĞ³Ğ¸Ğ¾Ğ½ '{region_name}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½ Ğ² Ğ‘Ğ”")
            return
        
        print(f"âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½: {region.name} (ID: {region.id})")
        
        # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ°
        existing_result = await db.execute(
            select(City.name).where(City.region_id == region.id)
        )
        existing_names = {city[0].lower().strip() for city in existing_result.all()}
        
        print(f"ğŸ“Š Ğ£Ğ¶Ğµ ĞµÑÑ‚ÑŒ Ğ² Ğ‘Ğ”: {len(existing_names)} Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ¾Ğ²")
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğµ (Ğ‘Ğ•Ğ— ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ ID - Ğ°Ğ²Ñ‚Ğ¾Ğ¸Ğ½ĞºÑ€ĞµĞ¼ĞµĞ½Ñ‚)
        added_count = 0
        skipped_count = 0
        
        for city_name in cities_list:
            city_key = city_name.lower().strip()
            
            if city_key in existing_names:
                skipped_count += 1
                continue
            
            new_city = City(
                # ĞĞ• ÑƒĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ id - Ğ°Ğ²Ñ‚Ğ¾Ğ¸Ğ½ĞºÑ€ĞµĞ¼ĞµĞ½Ñ‚!
                region_id=region.id,
                federal_district_id=region.federal_district_id,
                country_id=region.country_id,
                name=city_name,
                population=0,
                is_million_city=False,
                is_regional_center=False,
                is_active=True,
                created_at=datetime.now(),
                updated_at=datetime.now()
            )
            db.add(new_city)
            added_count += 1
            existing_names.add(city_key)
        
        await db.commit()
        
        print(f"\nâœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ¾Ğ²: {added_count}")
        print(f"â­ï¸  ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ (ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‚): {skipped_count}")
        
        # Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°
        result = await db.execute(
            select(City).where(City.region_id == region.id)
        )
        total_cities = result.scalars().all()
        print(f"ğŸ‰ Ğ’ÑĞµĞ³Ğ¾ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ¾Ğ²: {len(total_cities)}")


async def main():
    # Ğ¯Ñ€Ğ¾ÑĞ»Ğ°Ğ²ÑĞºĞ°Ñ Ğ¾Ğ±Ğ». - Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ²ÑĞµĞ³Ğ¾ Ğ³Ğ¾Ñ€Ğ¾Ğ´Ğ¾Ğ² (23)
    # ID Ğ½Ğ° superresearch.ru Ğ´Ğ»Ñ Ğ¯Ñ€Ğ¾ÑĞ»Ğ°Ğ²ÑĞºĞ¾Ğ¹ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸: 810
    await add_cities_for_region("Ğ¯Ñ€Ğ¾ÑĞ»Ğ°Ğ²ÑĞºĞ°Ñ Ğ¾Ğ±Ğ».", 810)


if __name__ == "__main__":
    asyncio.run(main())

